--------------------------------------
Running PBS prologue script
--------------------------------------
User and Job Data:
--------------------------------------
Job ID:    656145.qb3
Username:  fchen14
Group:     loniadmin
Date:      09-Jun-2019 09:26
Node:      qb089 (72875)
--------------------------------------
PBS has allocated the following nodes:

qb089
qb095
qb096
qb098

A total of 80 processors on 4 nodes allocated
---------------------------------------------
Check nodes and clean them of stray processes
---------------------------------------------
Checking node qb089 09:26:26 
Checking node qb095 09:26:28 
Checking node qb096 09:26:29 
Checking node qb098 09:26:31 
Done clearing all the allocated nodes
------------------------------------------------------
Concluding PBS prologue script - 09-Jun-2019 09:26:31
------------------------------------------------------
using 8 processes...
--------------------------------
Proc 4: *** testing PHDF5 dataset collective read...
--------------------------------
Input file is: hdf5t/sample_a-b_mix_2.h5
Output file is: hdf5t/sample_a-b_mix_2.h5.res_all.h5
--------------------------------
Proc 0: *** testing PHDF5 dataset collective read...
--------------------------------
--------------------------------
Proc 5: *** testing PHDF5 dataset collective read...
--------------------------------
--------------------------------
Proc 2: *** testing PHDF5 dataset collective read...
--------------------------------
--------------------------------
Proc 1: *** testing PHDF5 dataset collective read...
--------------------------------
--------------------------------
Proc 3: *** testing PHDF5 dataset collective read...
--------------------------------
--------------------------------
Proc 6: *** testing PHDF5 dataset collective read...
--------------------------------
--------------------------------
Proc 7: *** testing PHDF5 dataset collective read...
--------------------------------
Reading time is 4.238
Elapsed time is 33.808
Writing time is 0.078
===================================
PHDF5 tests finished with no errors
===================================
omp run trd=5, 39 sec
--------------------------------
Proc 6: *** testing PHDF5 dataset collective read...
--------------------------------
--------------------------------
Proc 2: *** testing PHDF5 dataset collective read...
--------------------------------
--------------------------------
Proc 7: *** testing PHDF5 dataset collective read...
--------------------------------
--------------------------------
Proc 3: *** testing PHDF5 dataset collective read...
--------------------------------
Input file is: hdf5t/sample_a-b_mix_2.h5
Output file is: hdf5t/sample_a-b_mix_2.h5.res_all.h5
--------------------------------
Proc 0: *** testing PHDF5 dataset collective read...
--------------------------------
--------------------------------
Proc 1: *** testing PHDF5 dataset collective read...
--------------------------------
--------------------------------
Proc 4: *** testing PHDF5 dataset collective read...
--------------------------------
--------------------------------
Proc 5: *** testing PHDF5 dataset collective read...
--------------------------------
Reading time is 3.213
Elapsed time is 28.226
Writing time is 0.050
===================================
PHDF5 tests finished with no errors
===================================
omp run trd=10, 33 sec
Without hostfile option, hostnames must be specified on command line.
usage: mpirun_rsh [-v] [-sg group] [-rsh|-ssh] [-debug] -[tv] [-xterm] [-show] [-legacy] [-export] -np N(-hostfile hfile | h1 h2 ... hN) a.out args | -config configfile (-hostfile hfile | h1 h2 ... hN)]
Where:
	sg         => execute the processes as different group ID
	rsh        => to use rsh for connecting
	ssh        => to use ssh for connecting
	debug      => run each process under the control of gdb
	tv         => run each process under the control of totalview
	xterm      => run remote processes under xterm
	show       => show command for remote execution but don't run it
	legacy     => use old startup method (1 ssh/process)
	export     => automatically export environment to remote processes
	np         => specify the number of processes
	h1 h2...   => names of hosts where processes should run
or	hostfile   => name of file containing hosts, one per line
	a.out      => name of MPI binary
	args       => arguments for MPI binary
	config     => name of file containing the exe information: each line has the form -n numProc : exe args

omp run trd=5, 0 sec
Without hostfile option, hostnames must be specified on command line.
usage: mpirun_rsh [-v] [-sg group] [-rsh|-ssh] [-debug] -[tv] [-xterm] [-show] [-legacy] [-export] -np N(-hostfile hfile | h1 h2 ... hN) a.out args | -config configfile (-hostfile hfile | h1 h2 ... hN)]
Where:
	sg         => execute the processes as different group ID
	rsh        => to use rsh for connecting
	ssh        => to use ssh for connecting
	debug      => run each process under the control of gdb
	tv         => run each process under the control of totalview
	xterm      => run remote processes under xterm
	show       => show command for remote execution but don't run it
	legacy     => use old startup method (1 ssh/process)
	export     => automatically export environment to remote processes
	np         => specify the number of processes
	h1 h2...   => names of hosts where processes should run
or	hostfile   => name of file containing hosts, one per line
	a.out      => name of MPI binary
	args       => arguments for MPI binary
	config     => name of file containing the exe information: each line has the form -n numProc : exe args

omp run trd=10, 0 sec
------------------------------------------------------
Running PBS epilogue script    - 09-Jun-2019 09:27:44
------------------------------------------------------
Checking node qb089 (MS)
Checking node qb098 ok
Checking node qb096 ok
Checking node qb095 ok
Checking node qb089 ok
------------------------------------------------------
Concluding PBS epilogue script - 09-Jun-2019 09:27:51
------------------------------------------------------
Exit Status:     0
Job ID:          656145.qb3
Username:        fchen14
Group:           loniadmin
Job Name:        tn4_p8.mvp2.600.pbs
Session Id:      72874
Resource Limits: ncpus=1,neednodes=4:ppn=20,nodes=4:ppn=20,walltime=02:30:00
Resources Used:  cput=00:14:23,mem=10144kb,vmem=336004kb,walltime=00:01:13
Queue Used:      checkpt
Account String:  loni_loniadmin1
Node:            qb089
Process id:      73560
------------------------------------------------------
