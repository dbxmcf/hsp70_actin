--------------------------------------
Running PBS prologue script
--------------------------------------
User and Job Data:
--------------------------------------
Job ID:    656431.qb3
Username:  fchen14
Group:     loniadmin
Date:      10-Jun-2019 09:55
Node:      qb318 (20359)
--------------------------------------
PBS has allocated the following nodes:

qb318
qb319
qb320
qb323

A total of 80 processors on 4 nodes allocated
---------------------------------------------
Check nodes and clean them of stray processes
---------------------------------------------
Checking node qb318 09:55:27 
Checking node qb319 09:55:29 
Checking node qb320 09:55:30 
Checking node qb323 09:55:32 
Done clearing all the allocated nodes
------------------------------------------------------
Concluding PBS prologue script - 10-Jun-2019 09:55:32
------------------------------------------------------
using 8 processes...
--------------------------------------------------------------------------
WARNING: a request was made to bind a process. While the system
supports binding the process itself, at least one node does NOT
support binding memory to the process location.

  Node:  qb318

This is a warning only; your job will continue, though performance may
be degraded.
--------------------------------------------------------------------------
[qb318:20984] MCW rank 0 bound to socket 0[core 0[hwt 0]], socket 0[core 1[hwt 0]], socket 0[core 2[hwt 0]], socket 0[core 3[hwt 0]], socket 0[core 4[hwt 0]], socket 0[core 5[hwt 0]], socket 0[core 6[hwt 0]], socket 0[core 7[hwt 0]], socket 0[core 8[hwt 0]], socket 0[core 9[hwt 0]]: [B/B/B/B/B/B/B/B/B/B][./././././././././.]
[qb318:20984] MCW rank 1 bound to socket 1[core 10[hwt 0]], socket 1[core 11[hwt 0]], socket 1[core 12[hwt 0]], socket 1[core 13[hwt 0]], socket 1[core 14[hwt 0]], socket 1[core 15[hwt 0]], socket 1[core 16[hwt 0]], socket 1[core 17[hwt 0]], socket 1[core 18[hwt 0]], socket 1[core 19[hwt 0]]: [./././././././././.][B/B/B/B/B/B/B/B/B/B]
[qb319:11784] MCW rank 2 bound to socket 0[core 0[hwt 0]], socket 0[core 1[hwt 0]], socket 0[core 2[hwt 0]], socket 0[core 3[hwt 0]], socket 0[core 4[hwt 0]], socket 0[core 5[hwt 0]], socket 0[core 6[hwt 0]], socket 0[core 7[hwt 0]], socket 0[core 8[hwt 0]], socket 0[core 9[hwt 0]]: [B/B/B/B/B/B/B/B/B/B][./././././././././.]
[qb319:11784] MCW rank 3 bound to socket 1[core 10[hwt 0]], socket 1[core 11[hwt 0]], socket 1[core 12[hwt 0]], socket 1[core 13[hwt 0]], socket 1[core 14[hwt 0]], socket 1[core 15[hwt 0]], socket 1[core 16[hwt 0]], socket 1[core 17[hwt 0]], socket 1[core 18[hwt 0]], socket 1[core 19[hwt 0]]: [./././././././././.][B/B/B/B/B/B/B/B/B/B]
[qb323:118603] MCW rank 7 bound to socket 1[core 10[hwt 0]], socket 1[core 11[hwt 0]], socket 1[core 12[hwt 0]], socket 1[core 13[hwt 0]], socket 1[core 14[hwt 0]], socket 1[core 15[hwt 0]], socket 1[core 16[hwt 0]], socket 1[core 17[hwt 0]], socket 1[core 18[hwt 0]], socket 1[core 19[hwt 0]]: [./././././././././.][B/B/B/B/B/B/B/B/B/B]
[qb323:118603] MCW rank 6 bound to socket 0[core 0[hwt 0]], socket 0[core 1[hwt 0]], socket 0[core 2[hwt 0]], socket 0[core 3[hwt 0]], socket 0[core 4[hwt 0]], socket 0[core 5[hwt 0]], socket 0[core 6[hwt 0]], socket 0[core 7[hwt 0]], socket 0[core 8[hwt 0]], socket 0[core 9[hwt 0]]: [B/B/B/B/B/B/B/B/B/B][./././././././././.]
[qb320:58796] MCW rank 4 bound to socket 0[core 0[hwt 0]], socket 0[core 1[hwt 0]], socket 0[core 2[hwt 0]], socket 0[core 3[hwt 0]], socket 0[core 4[hwt 0]], socket 0[core 5[hwt 0]], socket 0[core 6[hwt 0]], socket 0[core 7[hwt 0]], socket 0[core 8[hwt 0]], socket 0[core 9[hwt 0]]: [B/B/B/B/B/B/B/B/B/B][./././././././././.]
[qb320:58796] MCW rank 5 bound to socket 1[core 10[hwt 0]], socket 1[core 11[hwt 0]], socket 1[core 12[hwt 0]], socket 1[core 13[hwt 0]], socket 1[core 14[hwt 0]], socket 1[core 15[hwt 0]], socket 1[core 16[hwt 0]], socket 1[core 17[hwt 0]], socket 1[core 18[hwt 0]], socket 1[core 19[hwt 0]]: [./././././././././.][B/B/B/B/B/B/B/B/B/B]
[1560178535.871158] [qb319:11857:0]         mxm.c:196  MXM  WARN  The 'ulimit -s' on the system is set to 'unlimited'. This may have negative performance implications. Please set the stack size to the default value (10240) 
[1560178535.871269] [qb319:11856:0]         mxm.c:196  MXM  WARN  The 'ulimit -s' on the system is set to 'unlimited'. This may have negative performance implications. Please set the stack size to the default value (10240) 
[1560178535.875747] [qb318:20989:0]         mxm.c:196  MXM  WARN  The 'ulimit -s' on the system is set to 'unlimited'. This may have negative performance implications. Please set the stack size to the default value (10240) 
[1560178535.875821] [qb318:20988:0]         mxm.c:196  MXM  WARN  The 'ulimit -s' on the system is set to 'unlimited'. This may have negative performance implications. Please set the stack size to the default value (10240) 
[1560178535.889968] [qb323:118673:0]         mxm.c:196  MXM  WARN  The 'ulimit -s' on the system is set to 'unlimited'. This may have negative performance implications. Please set the stack size to the default value (10240) 
[1560178535.889876] [qb323:118674:0]         mxm.c:196  MXM  WARN  The 'ulimit -s' on the system is set to 'unlimited'. This may have negative performance implications. Please set the stack size to the default value (10240) 
[1560178535.927474] [qb320:58867:0]         mxm.c:196  MXM  WARN  The 'ulimit -s' on the system is set to 'unlimited'. This may have negative performance implications. Please set the stack size to the default value (10240) 
[1560178535.927573] [qb320:58868:0]         mxm.c:196  MXM  WARN  The 'ulimit -s' on the system is set to 'unlimited'. This may have negative performance implications. Please set the stack size to the default value (10240) 
Input file is: hdf5t/sample_a-b_mix_2.h5
Output file is: hdf5t/sample_a-b_mix_2.h5.res_all.h5
--------------------------------
Proc 0: *** testing PHDF5 dataset collective read...
--------------------------------
--------------------------------
Proc 1: *** testing PHDF5 dataset collective read...
--------------------------------
--------------------------------
Proc 2: *** testing PHDF5 dataset collective read...
--------------------------------
--------------------------------
Proc 3: *** testing PHDF5 dataset collective read...
--------------------------------
--------------------------------
Proc 6: *** testing PHDF5 dataset collective read...
--------------------------------
--------------------------------
Proc 7: *** testing PHDF5 dataset collective read...
--------------------------------
--------------------------------
Proc 4: *** testing PHDF5 dataset collective read...
--------------------------------
--------------------------------
Proc 5: *** testing PHDF5 dataset collective read...
--------------------------------
Reading time is 3.600
Elapsed time is 29.282
Writing time is 0.134
===================================
PHDF5 tests finished with no errors
===================================
--------------------------------------------------------------------------
mpirun noticed that process rank 1 with PID 20989 on node qb318 exited on signal 11 (Segmentation fault).
--------------------------------------------------------------------------
2 total processes killed (some possibly by mpirun during cleanup)
omp run trd=5, 36 sec
--------------------------------------------------------------------------
WARNING: a request was made to bind a process. While the system
supports binding the process itself, at least one node does NOT
support binding memory to the process location.

  Node:  qb318

This is a warning only; your job will continue, though performance may
be degraded.
--------------------------------------------------------------------------
[qb318:21005] MCW rank 0 bound to socket 0[core 0[hwt 0]], socket 0[core 1[hwt 0]], socket 0[core 2[hwt 0]], socket 0[core 3[hwt 0]], socket 0[core 4[hwt 0]], socket 0[core 5[hwt 0]], socket 0[core 6[hwt 0]], socket 0[core 7[hwt 0]], socket 0[core 8[hwt 0]], socket 0[core 9[hwt 0]]: [B/B/B/B/B/B/B/B/B/B][./././././././././.]
[qb318:21005] MCW rank 1 bound to socket 1[core 10[hwt 0]], socket 1[core 11[hwt 0]], socket 1[core 12[hwt 0]], socket 1[core 13[hwt 0]], socket 1[core 14[hwt 0]], socket 1[core 15[hwt 0]], socket 1[core 16[hwt 0]], socket 1[core 17[hwt 0]], socket 1[core 18[hwt 0]], socket 1[core 19[hwt 0]]: [./././././././././.][B/B/B/B/B/B/B/B/B/B]
[qb319:11878] MCW rank 2 bound to socket 0[core 0[hwt 0]], socket 0[core 1[hwt 0]], socket 0[core 2[hwt 0]], socket 0[core 3[hwt 0]], socket 0[core 4[hwt 0]], socket 0[core 5[hwt 0]], socket 0[core 6[hwt 0]], socket 0[core 7[hwt 0]], socket 0[core 8[hwt 0]], socket 0[core 9[hwt 0]]: [B/B/B/B/B/B/B/B/B/B][./././././././././.]
[qb319:11878] MCW rank 3 bound to socket 1[core 10[hwt 0]], socket 1[core 11[hwt 0]], socket 1[core 12[hwt 0]], socket 1[core 13[hwt 0]], socket 1[core 14[hwt 0]], socket 1[core 15[hwt 0]], socket 1[core 16[hwt 0]], socket 1[core 17[hwt 0]], socket 1[core 18[hwt 0]], socket 1[core 19[hwt 0]]: [./././././././././.][B/B/B/B/B/B/B/B/B/B]
[qb323:118698] MCW rank 6 bound to socket 0[core 0[hwt 0]], socket 0[core 1[hwt 0]], socket 0[core 2[hwt 0]], socket 0[core 3[hwt 0]], socket 0[core 4[hwt 0]], socket 0[core 5[hwt 0]], socket 0[core 6[hwt 0]], socket 0[core 7[hwt 0]], socket 0[core 8[hwt 0]], socket 0[core 9[hwt 0]]: [B/B/B/B/B/B/B/B/B/B][./././././././././.]
[qb323:118698] MCW rank 7 bound to socket 1[core 10[hwt 0]], socket 1[core 11[hwt 0]], socket 1[core 12[hwt 0]], socket 1[core 13[hwt 0]], socket 1[core 14[hwt 0]], socket 1[core 15[hwt 0]], socket 1[core 16[hwt 0]], socket 1[core 17[hwt 0]], socket 1[core 18[hwt 0]], socket 1[core 19[hwt 0]]: [./././././././././.][B/B/B/B/B/B/B/B/B/B]
[qb320:58891] MCW rank 4 bound to socket 0[core 0[hwt 0]], socket 0[core 1[hwt 0]], socket 0[core 2[hwt 0]], socket 0[core 3[hwt 0]], socket 0[core 4[hwt 0]], socket 0[core 5[hwt 0]], socket 0[core 6[hwt 0]], socket 0[core 7[hwt 0]], socket 0[core 8[hwt 0]], socket 0[core 9[hwt 0]]: [B/B/B/B/B/B/B/B/B/B][./././././././././.]
[qb320:58891] MCW rank 5 bound to socket 1[core 10[hwt 0]], socket 1[core 11[hwt 0]], socket 1[core 12[hwt 0]], socket 1[core 13[hwt 0]], socket 1[core 14[hwt 0]], socket 1[core 15[hwt 0]], socket 1[core 16[hwt 0]], socket 1[core 17[hwt 0]], socket 1[core 18[hwt 0]], socket 1[core 19[hwt 0]]: [./././././././././.][B/B/B/B/B/B/B/B/B/B]
[1560178571.161256] [qb318:21009:0]         mxm.c:196  MXM  WARN  The 'ulimit -s' on the system is set to 'unlimited'. This may have negative performance implications. Please set the stack size to the default value (10240) 
[1560178571.161356] [qb318:21010:0]         mxm.c:196  MXM  WARN  The 'ulimit -s' on the system is set to 'unlimited'. This may have negative performance implications. Please set the stack size to the default value (10240) 
[1560178571.161441] [qb320:58961:0]         mxm.c:196  MXM  WARN  The 'ulimit -s' on the system is set to 'unlimited'. This may have negative performance implications. Please set the stack size to the default value (10240) 
[1560178571.160510] [qb323:118768:0]         mxm.c:196  MXM  WARN  The 'ulimit -s' on the system is set to 'unlimited'. This may have negative performance implications. Please set the stack size to the default value (10240) 
[1560178571.160421] [qb323:118769:0]         mxm.c:196  MXM  WARN  The 'ulimit -s' on the system is set to 'unlimited'. This may have negative performance implications. Please set the stack size to the default value (10240) 
[1560178571.162132] [qb320:58962:0]         mxm.c:196  MXM  WARN  The 'ulimit -s' on the system is set to 'unlimited'. This may have negative performance implications. Please set the stack size to the default value (10240) 
[1560178571.162667] [qb319:11949:0]         mxm.c:196  MXM  WARN  The 'ulimit -s' on the system is set to 'unlimited'. This may have negative performance implications. Please set the stack size to the default value (10240) 
[1560178571.162592] [qb319:11950:0]         mxm.c:196  MXM  WARN  The 'ulimit -s' on the system is set to 'unlimited'. This may have negative performance implications. Please set the stack size to the default value (10240) 
--------------------------------
Proc 1: *** testing PHDF5 dataset collective read...
--------------------------------
Input file is: hdf5t/sample_a-b_mix_2.h5
Output file is: hdf5t/sample_a-b_mix_2.h5.res_all.h5
--------------------------------
Proc 0: *** testing PHDF5 dataset collective read...
--------------------------------
--------------------------------
Proc 2: *** testing PHDF5 dataset collective read...
--------------------------------
--------------------------------
Proc 3: *** testing PHDF5 dataset collective read...
--------------------------------
--------------------------------
Proc 5: *** testing PHDF5 dataset collective read...
--------------------------------
--------------------------------
Proc 4: *** testing PHDF5 dataset collective read...
--------------------------------
--------------------------------
Proc 6: *** testing PHDF5 dataset collective read...
--------------------------------
--------------------------------
Proc 7: *** testing PHDF5 dataset collective read...
--------------------------------
Reading time is 3.110
Elapsed time is 14.849
Writing time is 0.064
===================================
PHDF5 tests finished with no errors
===================================
mpirun: abort is already in progress...hit ctrl-c again to forcibly terminate

Killed by signal 15.
------------------------------------------------------
Running PBS epilogue script    - 10-Jun-2019 10:44:30
------------------------------------------------------
Checking node qb318 (MS)
Checking node qb323 ok
Checking node qb320 ok
Checking node qb319 ok
Checking node qb318 ok
------------------------------------------------------
Concluding PBS epilogue script - 10-Jun-2019 10:44:37
------------------------------------------------------
Exit Status:     271
Job ID:          656431.qb3
Username:        fchen14
Group:           loniadmin
Job Name:        tn4_p8.ompi.600.pbs
Session Id:      20358
Resource Limits: ncpus=1,neednodes=4:ppn=20,nodes=4:ppn=20,walltime=02:30:00
Resources Used:  cput=00:09:57,mem=1584424kb,vmem=2725180kb,walltime=00:48:58
Queue Used:      checkpt
Account String:  loni_loniadmin1
Node:            qb318
Process id:      21826
------------------------------------------------------
